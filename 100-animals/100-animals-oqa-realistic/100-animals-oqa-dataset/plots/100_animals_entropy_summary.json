[
  {
    "model": "Claude Sonnet 4.5",
    "step": 1,
    "entropy_bits_mean": 6.459431618637297,
    "entropy_bits_std": 0.0,
    "entropy_bits_lo": 6.459431618637297,
    "entropy_bits_hi": 6.459431618637297
  },
  {
    "model": "GPT 5",
    "step": 1,
    "entropy_bits_mean": 6.491853096329675,
    "entropy_bits_std": 0.0,
    "entropy_bits_lo": 6.491853096329675,
    "entropy_bits_hi": 6.491853096329675
  },
  {
    "model": "Gemini 2.5 Pro",
    "step": 1,
    "entropy_bits_mean": 6.569855608330948,
    "entropy_bits_std": 0.0,
    "entropy_bits_lo": 6.569855608330948,
    "entropy_bits_hi": 6.569855608330948
  },
  {
    "model": "Grok 4",
    "step": 1,
    "entropy_bits_mean": 6.523561956057013,
    "entropy_bits_std": 0.0,
    "entropy_bits_lo": 6.523561956057013,
    "entropy_bits_hi": 6.523561956057013
  },
  {
    "model": "Oracle",
    "step": 1,
    "entropy_bits_mean": 6.321928094887363,
    "entropy_bits_std": 0.0,
    "entropy_bits_lo": 6.321928094887363,
    "entropy_bits_hi": 6.321928094887363
  },
  {
    "model": "Claude Sonnet 4.5",
    "step": 2,
    "entropy_bits_mean": 5.977279923499917,
    "entropy_bits_std": 0.10434918976878564,
    "entropy_bits_lo": 5.832890014164741,
    "entropy_bits_hi": 6.129283016944966
  },
  {
    "model": "GPT 5",
    "step": 2,
    "entropy_bits_mean": 5.906890595608519,
    "entropy_bits_std": 0.10147154940498951,
    "entropy_bits_lo": 5.807354922057604,
    "entropy_bits_hi": 6.108524456778169
  },
  {
    "model": "Gemini 2.5 Pro",
    "step": 2,
    "entropy_bits_mean": 5.930737337562887,
    "entropy_bits_std": 0.0,
    "entropy_bits_lo": 5.930737337562887,
    "entropy_bits_hi": 5.930737337562887
  },
  {
    "model": "Grok 4",
    "step": 2,
    "entropy_bits_mean": 5.954196310386875,
    "entropy_bits_std": 0.15070967923287357,
    "entropy_bits_lo": 5.754887502163468,
    "entropy_bits_hi": 6.189824558880018
  },
  {
    "model": "Oracle",
    "step": 2,
    "entropy_bits_mean": 5.882643049361842,
    "entropy_bits_std": 0.20718611229261905,
    "entropy_bits_lo": 5.554588851677638,
    "entropy_bits_hi": 6.129283016944966
  },
  {
    "model": "Claude Sonnet 4.5",
    "step": 3,
    "entropy_bits_mean": 5.20945336562895,
    "entropy_bits_std": 0.14308102252915617,
    "entropy_bits_lo": 5.044394119358453,
    "entropy_bits_hi": 5.459431618637297
  },
  {
    "model": "GPT 5",
    "step": 3,
    "entropy_bits_mean": 5.087462841250339,
    "entropy_bits_std": 0.19546303729970677,
    "entropy_bits_lo": 4.754887502163468,
    "entropy_bits_hi": 5.321928094887363
  },
  {
    "model": "Gemini 2.5 Pro",
    "step": 3,
    "entropy_bits_mean": 5.321928094887363,
    "entropy_bits_std": 0.0,
    "entropy_bits_lo": 5.321928094887363,
    "entropy_bits_hi": 5.321928094887363
  },
  {
    "model": "Grok 4",
    "step": 3,
    "entropy_bits_mean": 5.20945336562895,
    "entropy_bits_std": 0.2736916227758326,
    "entropy_bits_lo": 4.857980995127572,
    "entropy_bits_hi": 5.643856189774724
  },
  {
    "model": "Oracle",
    "step": 3,
    "entropy_bits_mean": 5.044394119358453,
    "entropy_bits_std": 0.3208197140699881,
    "entropy_bits_lo": 4.584962500721156,
    "entropy_bits_hi": 5.523561956057013
  },
  {
    "model": "Claude Sonnet 4.5",
    "step": 4,
    "entropy_bits_mean": 4.392317422778761,
    "entropy_bits_std": 0.21958370285300735,
    "entropy_bits_lo": 4.087462841250339,
    "entropy_bits_hi": 4.643856189774724
  },
  {
    "model": "GPT 5",
    "step": 4,
    "entropy_bits_mean": 4.169925001442312,
    "entropy_bits_std": 0.3195867351349825,
    "entropy_bits_lo": 3.700439718141092,
    "entropy_bits_hi": 4.700439718141092
  },
  {
    "model": "Gemini 2.5 Pro",
    "step": 4,
    "entropy_bits_mean": 4.643856189774724,
    "entropy_bits_std": 0.0,
    "entropy_bits_lo": 4.643856189774724,
    "entropy_bits_hi": 4.643856189774724
  },
  {
    "model": "Grok 4",
    "step": 4,
    "entropy_bits_mean": 4.392317422778761,
    "entropy_bits_std": 0.4023373101525208,
    "entropy_bits_lo": 3.807354922057604,
    "entropy_bits_hi": 4.906890595608519
  },
  {
    "model": "Oracle",
    "step": 4,
    "entropy_bits_mean": 4.0,
    "entropy_bits_std": 0.42266504059705395,
    "entropy_bits_lo": 3.4594316186372973,
    "entropy_bits_hi": 4.807354922057604
  },
  {
    "model": "Claude Sonnet 4.5",
    "step": 5,
    "entropy_bits_mean": 3.4594316186372973,
    "entropy_bits_std": 0.3212065860962405,
    "entropy_bits_lo": 3.0,
    "entropy_bits_hi": 3.9068905956085187
  },
  {
    "model": "GPT 5",
    "step": 5,
    "entropy_bits_mean": 3.169925001442312,
    "entropy_bits_std": 0.43869749196283814,
    "entropy_bits_lo": 2.584962500721156,
    "entropy_bits_hi": 3.9068905956085187
  },
  {
    "model": "Gemini 2.5 Pro",
    "step": 5,
    "entropy_bits_mean": 3.584962500721156,
    "entropy_bits_std": 0.0,
    "entropy_bits_lo": 3.584962500721156,
    "entropy_bits_hi": 3.584962500721156
  },
  {
    "model": "Grok 4",
    "step": 5,
    "entropy_bits_mean": 3.321928094887362,
    "entropy_bits_std": 0.5424159758833691,
    "entropy_bits_lo": 2.584962500721156,
    "entropy_bits_hi": 4.0
  },
  {
    "model": "Oracle",
    "step": 5,
    "entropy_bits_mean": 2.807354922057604,
    "entropy_bits_std": 0.6082297406673052,
    "entropy_bits_lo": 2.0,
    "entropy_bits_hi": 4.0
  },
  {
    "model": "Claude Sonnet 4.5",
    "step": 6,
    "entropy_bits_mean": 2.321928094887362,
    "entropy_bits_std": 0.5205321505961645,
    "entropy_bits_lo": 1.584962500721156,
    "entropy_bits_hi": 3.169925001442312
  },
  {
    "model": "GPT 5",
    "step": 6,
    "entropy_bits_mean": 1.2,
    "entropy_bits_std": 0.4216370213557839,
    "entropy_bits_lo": 1.0,
    "entropy_bits_hi": 2.0
  },
  {
    "model": "Gemini 2.5 Pro",
    "step": 6,
    "entropy_bits_mean": 2.0,
    "entropy_bits_std": 0.0,
    "entropy_bits_lo": 2.0,
    "entropy_bits_hi": 2.0
  },
  {
    "model": "Grok 4",
    "step": 6,
    "entropy_bits_mean": 2.321928094887362,
    "entropy_bits_std": 0.8048695524515276,
    "entropy_bits_lo": 1.0,
    "entropy_bits_hi": 3.169925001442312
  },
  {
    "model": "Oracle",
    "step": 6,
    "entropy_bits_mean": 0.2,
    "entropy_bits_std": 0.4216370213557839,
    "entropy_bits_lo": 0.0,
    "entropy_bits_hi": 1.0
  },
  {
    "model": "Claude Sonnet 4.5",
    "step": 7,
    "entropy_bits_mean": 0.3,
    "entropy_bits_std": 0.48304589153964794,
    "entropy_bits_lo": 0.0,
    "entropy_bits_hi": 1.0
  },
  {
    "model": "GPT 5",
    "step": 7,
    "entropy_bits_mean": 0.3,
    "entropy_bits_std": 0.48304589153964794,
    "entropy_bits_lo": 0.0,
    "entropy_bits_hi": 1.0
  },
  {
    "model": "Gemini 2.5 Pro",
    "step": 7,
    "entropy_bits_mean": 0.3,
    "entropy_bits_std": 0.48304589153964794,
    "entropy_bits_lo": 0.0,
    "entropy_bits_hi": 1.0
  },
  {
    "model": "Grok 4",
    "step": 7,
    "entropy_bits_mean": 0.3,
    "entropy_bits_std": 0.48304589153964794,
    "entropy_bits_lo": 0.0,
    "entropy_bits_hi": 1.0
  },
  {
    "model": "Oracle",
    "step": 7,
    "entropy_bits_mean": 0.2,
    "entropy_bits_std": 0.4216370213557839,
    "entropy_bits_lo": 0.0,
    "entropy_bits_hi": 1.0
  },
  {
    "model": "Claude Sonnet 4.5",
    "step": 8,
    "entropy_bits_mean": 0.3,
    "entropy_bits_std": 0.48304589153964794,
    "entropy_bits_lo": 0.0,
    "entropy_bits_hi": 1.0
  },
  {
    "model": "GPT 5",
    "step": 8,
    "entropy_bits_mean": 0.3,
    "entropy_bits_std": 0.48304589153964794,
    "entropy_bits_lo": 0.0,
    "entropy_bits_hi": 1.0
  },
  {
    "model": "Gemini 2.5 Pro",
    "step": 8,
    "entropy_bits_mean": 0.3,
    "entropy_bits_std": 0.48304589153964794,
    "entropy_bits_lo": 0.0,
    "entropy_bits_hi": 1.0
  },
  {
    "model": "Grok 4",
    "step": 8,
    "entropy_bits_mean": 0.3,
    "entropy_bits_std": 0.48304589153964794,
    "entropy_bits_lo": 0.0,
    "entropy_bits_hi": 1.0
  },
  {
    "model": "Oracle",
    "step": 8,
    "entropy_bits_mean": 0.2,
    "entropy_bits_std": 0.4216370213557839,
    "entropy_bits_lo": 0.0,
    "entropy_bits_hi": 1.0
  },
  {
    "model": "Claude Sonnet 4.5",
    "step": 9,
    "entropy_bits_mean": 0.3,
    "entropy_bits_std": 0.48304589153964794,
    "entropy_bits_lo": 0.0,
    "entropy_bits_hi": 1.0
  },
  {
    "model": "GPT 5",
    "step": 9,
    "entropy_bits_mean": 0.3,
    "entropy_bits_std": 0.48304589153964794,
    "entropy_bits_lo": 0.0,
    "entropy_bits_hi": 1.0
  },
  {
    "model": "Gemini 2.5 Pro",
    "step": 9,
    "entropy_bits_mean": 0.3,
    "entropy_bits_std": 0.48304589153964794,
    "entropy_bits_lo": 0.0,
    "entropy_bits_hi": 1.0
  },
  {
    "model": "Grok 4",
    "step": 9,
    "entropy_bits_mean": 0.3,
    "entropy_bits_std": 0.48304589153964794,
    "entropy_bits_lo": 0.0,
    "entropy_bits_hi": 1.0
  },
  {
    "model": "Oracle",
    "step": 9,
    "entropy_bits_mean": 0.2,
    "entropy_bits_std": 0.4216370213557839,
    "entropy_bits_lo": 0.0,
    "entropy_bits_hi": 1.0
  }
]